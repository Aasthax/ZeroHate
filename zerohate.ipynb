{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESGD3Ka0bP3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ad61da-01b6-4ded-e78a-c61cb3da94c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.2579 - accuracy: 0.8263 - val_loss: 0.6483 - val_accuracy: 0.8300\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 39s 2s/step - loss: 0.4927 - accuracy: 0.8725 - val_loss: 0.6570 - val_accuracy: 0.8300\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 36s 1s/step - loss: 0.4689 - accuracy: 0.8725 - val_loss: 0.6241 - val_accuracy: 0.8300\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 37s 1s/step - loss: 0.4561 - accuracy: 0.8725 - val_loss: 0.6129 - val_accuracy: 0.8300\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 37s 1s/step - loss: 0.4339 - accuracy: 0.8725 - val_loss: 0.6116 - val_accuracy: 0.8300\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 38s 2s/step - loss: 0.3869 - accuracy: 0.8725 - val_loss: 0.5942 - val_accuracy: 0.8300\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 37s 2s/step - loss: 0.3216 - accuracy: 0.8750 - val_loss: 0.6229 - val_accuracy: 0.8350\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 44s 2s/step - loss: 0.2363 - accuracy: 0.9413 - val_loss: 0.6927 - val_accuracy: 0.8350\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 38s 1s/step - loss: 0.1541 - accuracy: 0.9688 - val_loss: 0.7021 - val_accuracy: 0.8250\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 39s 2s/step - loss: 0.1083 - accuracy: 0.9825 - val_loss: 0.8999 - val_accuracy: 0.8300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json\n",
        "\n",
        "# Load the dataset from an Excel file\n",
        "dataset = pd.read_excel('your_dataset.xlsx')\n",
        "\n",
        "# Assuming 'Comment' is the column with text data\n",
        "# And the rest of the columns are categories as one-hot encoded labels\n",
        "text_column = 'Text'\n",
        "label_columns = [\"racial_hate\", \"Religious_caste_hate\", \"sexual_orientation_hate\", \"gender_based_hate\",\n",
        "                 \"disability_hate\", \"political_hate\", \"social_caste_hate\", \"age_based_hate\",\n",
        "                 \"nationality_hate\", \"appearance_based_hate\", \"none\"]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    dataset[text_column], dataset[label_columns], test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the text data\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "max_sequence_length = max(max([len(sequence) for sequence in train_sequences]), max([len(sequence) for sequence in test_sequences]))\n",
        "train_data = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
        "test_data = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Assuming the model structure can remain the same\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 100, input_length=max_sequence_length))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(len(label_columns), activation='softmax'))  # Update the number of outputs to match the number of categories\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',  # Update the loss function for multi-label classification\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_data, train_labels, validation_data=(test_data, test_labels), epochs=10, batch_size=32)\n",
        "\n",
        "# Save the trained model and tokenizer\n",
        "model.save('/content/hate_speech_classification_model_updated.h5')\n",
        "\n",
        "tokenizer_json = tokenizer.to_json()\n",
        "with open('/content/tokenizer_updated.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
        "\n",
        "# Note: For label decoding, since we're dealing with multi-label classification,\n",
        "# the approach will differ. You might want to threshold the output probabilities to determine label assignments.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Making predictions with the model\n",
        "def make_predictions(text):\n",
        "    # Preprocess the text\n",
        "    encoded_text = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=max_sequence_length)\n",
        "\n",
        "    # Predict\n",
        "    predictions = model.predict(encoded_text)\n",
        "\n",
        "    # Apply a threshold to each label\n",
        "    threshold = 0.5\n",
        "    labels = (predictions > threshold).astype(int)\n",
        "\n",
        "    # Map back to label names\n",
        "    predicted_labels = [label_columns[i] for i, label in enumerate(labels[0]) if label == 1]\n",
        "\n",
        "    return predicted_labels\n",
        "\n",
        "# Example usage\n",
        "new_text = \"Stats don`t represent the problem. Race baiting and attitude is. Who`s doing the crimes ? Ohh I bet Trayvon is still the little innocent boy too. Don`t speak with a lisp, a sure sign of a left wing democrat ! \"\n",
        "predicted_labels = make_predictions(new_text)\n",
        "print(f\"Predicted Labels for '{new_text}': {predicted_labels}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgqPEsyFf7pH",
        "outputId": "3a798cd9-f2dc-44aa-cd39-b869c56f46a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 193ms/step - loss: 0.8999 - accuracy: 0.8300\n",
            "Test Loss: 0.8999078869819641, Test Accuracy: 0.8299999833106995\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Predicted Labels for 'Stats don`t represent the problem. Race baiting and attitude is. Who`s doing the crimes ? Ohh I bet Trayvon is still the little innocent boy too. Don`t speak with a lisp, a sure sign of a left wing democrat ! ': ['racial_hate']\n"
          ]
        }
      ]
    }
  ]
}